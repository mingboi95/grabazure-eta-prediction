{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required packages in Azure notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install pyshp\n",
    "!pip install descartes\n",
    "!pip install fiona\n",
    "!pip install shapely\n",
    "!pip install pyproj\n",
    "!pip install \"rtree>=0.8,<0.9\"\n",
    "!sudo apt install python3-rtree -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from math import radians, cos, sin, asin, sqrt, atan2, pi\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import shapefile\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "import rtree\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeGroup(hour):\n",
    "    if hour <= 7:\n",
    "        return 'late night'\n",
    "    elif hour <= 9:\n",
    "        return 'morning peak'\n",
    "    elif hour <= 18:\n",
    "        return 'day'\n",
    "    elif hour <= 20:\n",
    "        return 'evening peak'\n",
    "    elif hour <= 23:\n",
    "        return 'night'\n",
    "\n",
    "def GetDistance(orilat, orilng, deslat, deslng):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [orilng, orilat, deslng, deslat])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    return 2 * asin(sqrt(sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2)) * 6371e3\n",
    "\n",
    "def GetSubregion(lat, long):\n",
    "    \n",
    "    global gdf\n",
    "    \n",
    "    for i in range(len(gdf)):\n",
    "        if Point(long, lat).within(gdf.geometry.iloc[i]):\n",
    "            return gdf.PLN_AREA_N.iloc[i]\n",
    "    return 'BISHAN' # BISHAN is deemed to have a central location in Singapore and therefore used as the 'average' \n",
    "\n",
    "def GetWeather(day, month, subregion):\n",
    "    \n",
    "    global subregion_exceptions\n",
    "    global weather\n",
    "    \n",
    "    temp = subregion_exceptions[subregion] if subregion in subregion_exceptions else subregion\n",
    "        \n",
    "    mask = (weather.weather_day == day) & (weather.weather_month == month) & (weather.subregion == temp)\n",
    "    DF = weather.loc[mask]\n",
    "    \n",
    "    if len(DF) > 1:\n",
    "        mask = (weather.weather_day == day) & (weather.weather_month == month)\n",
    "        return weather.loc[mask].Rainfall.mean(skipna=True)\n",
    "    elif len(DF) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return DF.Rainfall.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing spatial and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile = ZipFile('planning-area-census2010-shp.zip')\n",
    "filenames = [y for y in sorted(zipfile.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "\n",
    "dbf, prj, shp, shx = [BytesIO(zipfile.read(filename)) for filename in filenames]\n",
    "r = shapefile.Reader(shp=shp, shx=shx, dbf=dbf)\n",
    "\n",
    "attributes, geometry = [], []\n",
    "field_names = [field[0] for field in r.fields[1:]]  \n",
    "for row in r.shapeRecords():  \n",
    "    geometry.append(shape(row.shape.__geo_interface__))  \n",
    "    attributes.append(dict(zip(field_names, row.record)))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(data = attributes, geometry = geometry, crs = 'epsg:3414')\n",
    "gdf.geometry = gdf.geometry.to_crs(epsg=4326)\n",
    "\n",
    "weather = pd.read_csv('may_apr_weather.csv')\n",
    "\n",
    "subregion_exceptions = {\n",
    "    'BUKIT BATOK': 'BUKIT PANJANG',\n",
    "    'HOUGANG': 'PAYA LEBAR',\n",
    "    'JURONG EAST': 'CLEMENTI',\n",
    "    'MARINA EAST': 'MARINA SOUTH',\n",
    "    'OUTRAM': 'MARINA SOUTH',\n",
    "    'STRAITS VIEW': 'MARINA SOUTH',\n",
    "    'MUSEUM': 'DOWNTOWN CORE',\n",
    "    'ROCHOR': 'DOWNTOWN CORE',\n",
    "    'SINGAPORE RIVER': 'DOWNTOWN CORE',\n",
    "    'RIVER VALLEY': 'ORCHARD',\n",
    "    'TANGLIN': 'ORCHARD',\n",
    "    'SENGKANG': 'SELETAR',\n",
    "    'SIMPANG': 'SEMBAWANG',\n",
    "    'WESTERN ISLANDS': 'BOON LAY',\n",
    "    'WESTERN WATER CATCHMENT': 'LIM CHU KANG'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following function to get prediction for 1 input at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, endpoint):\n",
    "        \n",
    "    '''Returns a prediction for 1 data point at a time\n",
    "    Inputs:\n",
    "        test: single json object with:\n",
    "            lattitude_origin\n",
    "            longitude_origin\n",
    "            lattitude_destination\n",
    "            longitude_destination\n",
    "            timestamp\n",
    "            hour_of_day\n",
    "            day_of_week\n",
    "        endpoint: endpoint string'''\n",
    "    \n",
    "    global gdf\n",
    "    global weather\n",
    "    \n",
    "    timestamp = test[\"timestamp\"]\n",
    "    day = datetime.datetime.fromtimestamp(timestamp).day\n",
    "    month = datetime.datetime.fromtimestamp(timestamp).month\n",
    "    \n",
    "    x = [\n",
    "        1 if test[\"day_of_week\"] <= 4 else 0,\n",
    "        test[\"hour_of_day\"],\n",
    "        TimeGroup(test[\"hour_of_day\"]),\n",
    "        GetWeather(day, month, GetSubregion(test[\"lattitude_origin\"], test[\"longitude_origin\"])),\n",
    "        GetWeather(day, month, GetSubregion(test[\"lattitude_destination\"], test[\"longitude_destination\"])),\n",
    "        test[\"lattitude_origin\"],\n",
    "        test[\"longitude_origin\"],\n",
    "        test[\"lattitude_destination\"],\n",
    "        test[\"longitude_destination\"],\n",
    "        GetDistance(test[\"lattitude_origin\"], test[\"longitude_origin\"], test[\"lattitude_destination\"], test[\"longitude_destination\"])\n",
    "    ]\n",
    "        \n",
    "    #Convert the array to JSON format\n",
    "    input_json = json.dumps({\"data\": [x]})\n",
    "\n",
    "    #Set the content type and authentication for the request\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    #Send the request\n",
    "    response = requests.post(endpoint, input_json, headers=headers)\n",
    "\n",
    "    #If we got a valid response, display the predictions    \n",
    "    return int(round(json.loads(response.json())[\"result\"][0], 0)) if response.status_code == 200 else 1252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making use of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'http://f735fbd3-2bf1-4505-99f3-ea2fac35cef9.southeastasia.azurecontainer.io/score'\n",
    "\n",
    "'''\n",
    "Input data should be a list of json objects\n",
    "    each json object should have those attributes as specified:\n",
    "            lattitude_origin\n",
    "            longitude_origin\n",
    "            lattitude_destination\n",
    "            longitude_destination\n",
    "            timestamp\n",
    "            hour_of_day\n",
    "            day_of_week\n",
    "'''\n",
    "\n",
    "test_data = [\n",
    "    {\"lattitude_origin\": -6.141255,\n",
    "    \"longitude_origin\": 106.692710,\n",
    "    \"lattitude_destination\": -6.141150,\n",
    "    \"longitude_destination\": 106.693154,\n",
    "    \"timestamp\": 1590487113,\n",
    "    \"hour_of_day\": 9,\n",
    "    \"day_of_week\": 1},\n",
    "    \n",
    "    {\"lattitude_origin\": -6.141255,\n",
    "    \"longitude_origin\": 106.692710,\n",
    "    \"lattitude_destination\": -6.141150,\n",
    "    \"longitude_destination\": 106.693154,\n",
    "    \"timestamp\": 1590488113,\n",
    "    \"hour_of_day\": 23,\n",
    "    \"day_of_week\": 1},\n",
    "    \n",
    "    {\"lattitude_origin\": -6.141255,\n",
    "    \"longitude_origin\": 106.692710,\n",
    "    \"lattitude_destination\": -6.141150,\n",
    "    \"longitude_destination\": 106.693154,\n",
    "    \"timestamp\": 1590487113,\n",
    "    \"hour_of_day\": 9,\n",
    "    \"day_of_week\": 1}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1252, 1252, 1252]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using a simple for loop to populate the predictions array to calculate RMSE later on\n",
    "'''\n",
    "\n",
    "predictions = list()\n",
    "for i in range(len(test_data)):\n",
    "    predictions.append(predict(test_data[i], endpoint))\n",
    "    \n",
    "# Outputs the predictions in seconds\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
